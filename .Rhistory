d <- rbind(d, temp)
} else{
d <- temp
}
}
}
# save simulation output
write_csv(d, "simdata/W3_randomnoise.csv")
# Now we visualize it
p1 <- ggplot(d, aes(trial,
cumulativerate,
group = rate,
color = rate)) +
geom_line() +
geom_hline(yintercept = 0.5,
linetype = "dashed") +
ylim(0,1) +
facet_wrap(.~noise) +
theme_classic()
p1
# We subset to only include no noise and a specific rate
d1 <- d %>%
subset(noise == 0 & rate == 0.8) %>%
rename(Other = choice) %>%
mutate(cumulativerate = lag(cumulativerate, 1))
d1$cumulativerate[1] <- 0.5 # no prior info at first trial
d1$cumulativerate[d1$cumulativerate == 0] <- 0.01
d1$cumulativerate[d1$cumulativerate == 1] <- 0.99
# Now we create the memory agent with a coefficient of 0.9
MemoryAgent_f <- function(bias, beta, cumulativerate){
choice = rbinom(1, 1, inv_logit_scaled(bias + beta * cumulativerate))
return(choice)
}
d1$Self[1] <- RandomAgentNoise_f(0.5, 0)
for (i in 2:trials) {
d1$Self[i] <- MemoryAgent_f(bias = 0, beta = 0.8, d1$cumulativerate[i])
}
## Create the data
data <- list(
n = 120,
h = d1$Self,
memory = d1$cumulativerate # this creates the new parameter: the rate of right hands so far in log-odds
)
## Create the data
data <- list(
n = 120,
h = d1$Self,
other = d1$Other
)
stan_model <- "
// The input (data) for the model. n of trials and h for (right and left) hand
data {
int<lower=1> n;
array[n] int h;
array[n] int other;
}
// The parameters accepted by the model.
parameters {
real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)?
real beta; // how strongly is previous rate impacting the decision?
}
transformed parameters{
vector[n] memory;
for (trial in 1:n){
if (trial == 1) {
memory[trial] = 0.5;
}
if (trial < n){
memory[trial + 1] = memory[trial] + ((other[trial] - memory[trial]) / trial);
if (memory[trial + 1] == 0){memory[trial + 1] = 0.01;}
if (memory[trial + 1] == 1){memory[trial + 1] = 0.99;}
}
}
}
// The model to be estimated.
model {
// Priors
target += normal_lpdf(bias | 0, .3);
target += normal_lpdf(beta | 0, .5);
// Model, looping to keep track of memory
for (trial in 1:n) {
target += bernoulli_logit_lpmf(h[trial] | bias + beta * logit(memory[trial]));
}
}
"
write_stan_file(
stan_model,
dir = "stan/",
basename = "W3_InternalMemory.stan")
## Specify where the model is
file <- file.path("stan/W3_InternalMemory.stan")
mod <- cmdstan_model(file,
cpp_options = list(stan_threads = TRUE),
stanc_options = list("O1"))
# The following command calls Stan with specific options.
samples <- mod$sample(
data = data,
seed = 123,
chains = 1,
parallel_chains = 2,
threads_per_chain = 2,
iter_warmup = 1000,
iter_sampling = 1000,
refresh = 0,
max_treedepth = 20,
adapt_delta = 0.99,
)
samples$summary()
stan_model <- "
// The input (data) for the model. n of trials and h for (right and left) hand
data {
int<lower=1> n;
array[n] int h;
array[n] int other;
}
// The parameters accepted by the model.
parameters {
real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)?
real beta; // how strongly is previous rate impacting the decision?
real<lower=0, upper=1> forgetting;
}
// The model to be estimated.
model {
vector[n] memory;
// Priors
target += beta_lpdf(forgetting | 1, 1);
target += normal_lpdf(bias | 0, .3);
target += normal_lpdf(beta | 0, .5);
// Model, looping to keep track of memory
for (trial in 1:n) {
if (trial == 1) {
memory[trial] = 0.5;
}
target += bernoulli_logit_lpmf(h[trial] | bias + beta * logit(memory[trial]));
if (trial < n){
memory[trial + 1] = (1 - forgetting) * memory[trial] + forgetting * other[trial];
if (memory[trial + 1] == 0){memory[trial + 1] = 0.01;}
if (memory[trial + 1] == 1){memory[trial + 1] = 0.99;}
}
}
}
"
write_stan_file(
stan_model,
dir = "stan/",
basename = "W3_InternalMemory2.stan")
## Specify where the model is
file <- file.path("stan/W3_InternalMemory2.stan")
mod <- cmdstan_model(file,
cpp_options = list(stan_threads = TRUE),
stanc_options = list("O1"))
# The following command calls Stan with specific options.
samples <- mod$sample(
data = data,
seed = 123,
chains = 1,
parallel_chains = 2,
threads_per_chain = 2,
iter_warmup = 1000,
iter_sampling = 1000,
refresh = 0,
max_treedepth = 20,
adapt_delta = 0.99,
)
pacman::p_load(tidyverse, rstan)
trials <- 120
rate <- 0.5
# now as a function
RandomAgent_f <- function(input, rate){
n <- length(input)
choice <- rbinom(n, 1, rate)
return(choice)
}
trials <- 120
rate <- 0.5
# now as a function
RandomAgent_f <- function(input, rate){
n <- length(input)
choice <- rbinom(n, 1, rate)
return(choice)
}
# Building function for asymmetric win stay loose shift agent by including probabilities for winning and loosing
AsymWSLSAgent_f <- function(prevChoice, Feedback, winProb, lossProb){
if (Feedback == 1){
randomness <- rbinom(1, 1, winProb)
# stay with choice agent would initially have made
if (randomness == 1){
choice = prevChoice
# randomly shift
} else if (randomness == 0){
choice = 1-prevChoice
}
} else if (Feedback == 0){
randomness <- rbinom(1, 1, lossProb)
# stay with choice agent would initially have made
if (randomness == 1){
choice = 1-prevChoice
# randomly shift
} else if (randomness == 0){
choice = prevChoice
}
}
return(choice)
}
# empty vectors for agents
Self <- rep(NA, trials)
Random <- rep(NA, trials)
Feedbacklist <- rep(NA, trials)
# other agent's choices
for (t in seq(trials)){
Random[t] <- RandomAgent_f(trials, rate)
}
# first choice is random...
Self[1] <- rbinom(1,1,0.5)
# all other choices
for (t in 2:trials){
# get feedback
if (Self[t-1] == Random[t-1]){
Feedback = 1
} else {Feedback = 0}
# register feedback
Feedbacklist[t] <- Feedback
# make decision
Self[t] <- AsymWSLSAgent_f(Self[t-1],
Feedback,
0.9, #Win probability
0.7) #Loose probability
}
# turn into tibble
WSLS_df <- tibble(Self,
Random,
trial = seq(trials),
Feedback_prevT = Feedbacklist)
hist(rbeta(1000, 1, 1))
rstan:::rstudio_stanc("WSLS.stan")
rstan:::rstudio_stanc("WSLS.stan")
pacman::p_load(tidyverse, rstan)
trials <- 120
rate <- 0.5
# now as a function
RandomAgent_f <- function(input, rate){
n <- length(input)
choice <- rbinom(n, 1, rate)
return(choice)
}
# Building function for asymmetric win stay loose shift agent by including probabilities for winning and loosing
AsymWSLSAgent_f <- function(prevChoice, Feedback, winProb, lossProb){
if (Feedback == 1){
randomness <- rbinom(1, 1, winProb)
# stay with choice agent would initially have made
if (randomness == 1){
choice = prevChoice
# randomly shift
} else if (randomness == 0){
choice = 1-prevChoice
}
} else if (Feedback == 0){
randomness <- rbinom(1, 1, lossProb)
# stay with choice agent would initially have made
if (randomness == 1){
choice = 1-prevChoice
# randomly shift
} else if (randomness == 0){
choice = prevChoice
}
}
return(choice)
}
# empty vectors for agents
Self <- rep(NA, trials)
Random <- rep(NA, trials)
Feedbacklist <- rep(NA, trials)
# other agent's choices
for (t in seq(trials)){
Random[t] <- RandomAgent_f(trials, rate)
}
# first choice is random...
Self[1] <- rbinom(1,1,0.5)
# all other choices
for (t in 2:trials){
# get feedback
if (Self[t-1] == Random[t-1]){
Feedback = 1
} else {Feedback = 0}
# register feedback
Feedbacklist[t] <- Feedback
# make decision
Self[t] <- AsymWSLSAgent_f(Self[t-1],
Feedback,
0.9, #Win probability
0.7) #Loose probability
}
# turn into tibble
WSLS_df <- tibble(Self,
Random,
trial = seq(trials),
Feedback_prevT = Feedbacklist)
View(WSLS_df)
## Specify where the model is
file <- file.path("stan/WSLS.stan")
# Compile the model
mod <- cmdstan_model(file,
# this specifies we can parallelize the gradient estimations on multiple cores
cpp_options = list(stan_threads = TRUE),
# this is a trick to make it faster
stanc_options = list("O1"))
pacman::p_load(tidyverse,
here,
posterior,
cmdstanr,
brms,
tidybayes,
future,
purrr,
furrr)
# Compile the model
mod <- cmdstan_model(file,
# this specifies we can parallelize the gradient estimations on multiple cores
cpp_options = list(stan_threads = TRUE),
# this is a trick to make it faster
stanc_options = list("O1"))
# The following command calls Stan with specific options.
samples <- mod$sample(
data = WSLS_df, # the data :-)
seed = 123,  # a seed, so I always get the same results
chains = 2,  # how many chains should I fit (to check whether they give the same results)
parallel_chains = 2, # how many of the chains can be run in parallel?
threads_per_chain = 2, # distribute gradient estimations within chain across multiple cores
iter_warmup = 1000,  # warmup iterations through which hyperparameters (steps and step length) are adjusted
iter_sampling = 2000, # total number of iterations
refresh = 0,  # how often to show that iterations have been run
output_dir = "simmodels", # saves the samples as csv so it can be later loaded
max_treedepth = 20, # how many steps in the future to check to avoid u-turns
adapt_delta = 0.99, # how high a learning rate to adjust hyperparameters during warmup
)
rstan:::rstudio_stanc("stan/WSLS.stan")
# Compile the model
mod <- cmdstan_model(file,
# this specifies we can parallelize the gradient estimations on multiple cores
cpp_options = list(stan_threads = TRUE),
# this is a trick to make it faster
stanc_options = list("O1"))
## Create the data. N.B. note the two variables have different lengths: 1 for n, n for h.
data <- list(
trials = 120, # 'trials' in data section of stan model
choices = WSLS_df$Self, # 'choices' in data section of stan model
feedback = WSLS_df$Feedback_prevT # 'feedback' in data section of stan model
)
# The following command calls Stan with specific options.
samples <- mod$sample(
data = data, # the data :-)
seed = 123,  # a seed, so I always get the same results
chains = 2,  # how many chains should I fit (to check whether they give the same results)
parallel_chains = 2, # how many of the chains can be run in parallel?
threads_per_chain = 2, # distribute gradient estimations within chain across multiple cores
iter_warmup = 1000,  # warmup iterations through which hyperparameters (steps and step length) are adjusted
iter_sampling = 2000, # total number of iterations
refresh = 0,  # how often to show that iterations have been run
output_dir = "simmodels", # saves the samples as csv so it can be later loaded
max_treedepth = 20, # how many steps in the future to check to avoid u-turns
adapt_delta = 0.99, # how high a learning rate to adjust hyperparameters during warmup
)
rstan:::rstudio_stanc("stan/WSLS.stan")
## Create the data. N.B. note the two variables have different lengths: 1 for n, n for h.
data <- list(
trials = 120, # 'trials' in data section of stan model
choices = WSLS_df$Self, # 'choices' in data section of stan model
feedback = WSLS_df$Feedback_prevT, # 'feedback' in data section of stan model
feedback_missing = NA_real_
)
# Compile the model
mod <- cmdstan_model(file,
# this specifies we can parallelize the gradient estimations on multiple cores
cpp_options = list(stan_threads = TRUE),
# this is a trick to make it faster
stanc_options = list("O1"))
# The following command calls Stan with specific options.
samples <- mod$sample(
data = data, # the data :-)
seed = 123,  # a seed, so I always get the same results
chains = 2,  # how many chains should I fit (to check whether they give the same results)
parallel_chains = 2, # how many of the chains can be run in parallel?
threads_per_chain = 2, # distribute gradient estimations within chain across multiple cores
iter_warmup = 1000,  # warmup iterations through which hyperparameters (steps and step length) are adjusted
iter_sampling = 2000, # total number of iterations
refresh = 0,  # how often to show that iterations have been run
output_dir = "simmodels", # saves the samples as csv so it can be later loaded
max_treedepth = 20, # how many steps in the future to check to avoid u-turns
adapt_delta = 0.99, # how high a learning rate to adjust hyperparameters during warmup
)
# Building function for asymmetric win stay loose shift agent by including probabilities for winning and loosing
AsymWSLSAgent_f <- function(prevChoice, Feedback, winProb, lossProb){
if (Feedback == 1){
randomness <- rbinom(1, 1, winProb)
# stay with choice agent would initially have made
if (randomness == 1){
choice = prevChoice
# randomly shift
} else if (randomness == 0){
choice = 1-prevChoice
}
} else if (Feedback == 0){
randomness <- rbinom(1, 1, lossProb)
# stay with choice agent would initially have made
if (randomness == 1){
choice = 1-prevChoice
# randomly shift
} else if (randomness == 0){
choice = prevChoice
}
}
return(choice)
}
# empty vectors for agents
Self <- rep(NA, trials)
Random <- rep(NA, trials)
Feedbacklist <- rep(NA, trials)
# other agent's choices
for (t in seq(trials)){
Random[t] <- RandomAgent_f(trials, rate)
}
# first choice is random...
Self[1] <- rbinom(1,1,0.5)
# all other choices
for (t in 2:trials){
# get feedback
if (Self[t-1] == Random[t-1]){
Feedback = 1
} else {Feedback = 0}
# register feedback
Feedbacklist[t-1] <- Feedback
# make decision
Self[t] <- AsymWSLSAgent_f(Self[t-1],
Feedback,
0.9, #Win probability
0.7) #Loose probability
}
if (Self[120] == Random[120]){
Feedbacklist[120] = 1
} else {Feedbacklist[120] = 0}
# turn into tibble
WSLS_df <- tibble(Self,
Random,
trial = seq(trials),
Feedback_prevT = Feedbacklist)
View(WSLS_df)
# turn into tibble
WSLS_df <- tibble(Self,
Random,
trial = seq(trials),
feedback = Feedbacklist)
## Create the data. N.B. note the two variables have different lengths: 1 for n, n for h.
data <- list(
trials = 120, # 'trials' in data section of stan model
choices = WSLS_df$Self, # 'choices' in data section of stan model
feedback = WSLS_df$feedback # 'feedback' in data section of stan model
)
## Specify where the model is
file <- file.path("stan/WSLS.stan")
# Compile the model
mod <- cmdstan_model(file,
# this specifies we can parallelize the gradient estimations on multiple cores
cpp_options = list(stan_threads = TRUE),
# this is a trick to make it faster
stanc_options = list("O1"))
# The following command calls Stan with specific options.
samples <- mod$sample(
data = data, # the data :-)
seed = 123,  # a seed, so I always get the same results
chains = 2,  # how many chains should I fit (to check whether they give the same results)
parallel_chains = 2, # how many of the chains can be run in parallel?
threads_per_chain = 2, # distribute gradient estimations within chain across multiple cores
iter_warmup = 1000,  # warmup iterations through which hyperparameters (steps and step length) are adjusted
iter_sampling = 2000, # total number of iterations
refresh = 0,  # how often to show that iterations have been run
output_dir = "simmodels", # saves the samples as csv so it can be later loaded
max_treedepth = 20, # how many steps in the future to check to avoid u-turns
adapt_delta = 0.99, # how high a learning rate to adjust hyperparameters during warmup
)
# Save the fitted model
samples$save_object("WSLS.rds")
samples <- readRDS("simmodels/W3_SimpleBernoulli.rds")
samples <- readRDS("simmodels/WSLS.rds")
# Save the fitted model
samples$save_object("simmodels/WSLS.rds")
samples <- readRDS("simmodels/WSLS.rds")
samples$summary() # summarize the model
samples$cmdstan_diagnose()
samples$summary() # summarize the model
ggplot(draws_df,
aes(.iteration,
winprob,
group = .chain,
color = .chain)) +
geom_line() +
theme_classic()
# Extract posterior samples and include sampling of the prior:
draws_df <- as_draws_df(samples$draws())
ggplot(draws_df,
aes(.iteration,
winprob,
group = .chain,
color = .chain)) +
geom_line() +
theme_classic()
ggplot(draws_df,
aes(.iteration,
lossprob,
group = .chain,
color = .chain)) +
geom_line() +
theme_classic()
